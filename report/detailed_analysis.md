# Детальный анализ результатов и ответы на критику

## 1. Источник данных

Датасет создан совместно с профессиональными юристами Республики Казахстан. Процесс сбора:

1. **Отбор вопросов**: Из реальных обращений пользователей на юридических платформах были отобраны наиболее типичные вопросы по казахстанскому законодательству
2. **Формирование ответов**: Профессиональные юристы составили эталонные ответы на каждый вопрос с корректными ссылками на НПА РК
3. **Формат**: Каждая пара оформлена в формате Alpaca (instruction/input/output) в JSONL
4. **Языки**: Русский (76.2%) и казахский (23.8%), что отражает реальную пропорцию обращений
5. **Объём**: 56,802 обучающих и 6,312 валидационных пар

---

## 2. Анализ Hallucination Rate (критика #2)

### 2.1 Почему Hallucination Rate растёт после fine-tuning?

| Показатель | Base 4B | FT 4B |
|-----------|---------|-------|
| Samples с hallucination > 0 | 117 (23.4%) | 159 (31.8%) |
| Samples с hallucination = 1.0 (полная) | **116** | **103** |
| Samples с частичной hallucination (0.25-0.88) | 1 | **56** |

**Ключевое наблюдение**: Base модель ведёт себя бинарно — она либо не цитирует статьи вообще (halluc=0), либо цитирует полностью неправильно (halluc=1.0). FT модель чаще генерирует ответы с несколькими цитатами, из которых часть правильная, а часть — нет. Это создаёт «частичные» галлюцинации (rate 0.25-0.88).

**Количество полностью неправильных ответов снизилось**: 116 → 103 (-11%). FT модель реже ошибается полностью, но чаще генерирует сложные ответы с микс-цитированием.

### 2.2 Таксономия ошибок галлюцинации

На основе анализа 50 примеров с hallucination_rate > 0 в FT модели:

| Тип ошибки | Описание | Доля |
|-----------|---------|------|
| **Неверный номер статьи** | Правильный закон, но ошибочный номер статьи (ст.15 вместо ст.28) | ~45% |
| **Неверный закон** | Ссылка на другой кодекс (НК вместо ГК) | ~25% |
| **Выдуманный пункт** | Несуществующий подпункт существующей статьи | ~20% |
| **Правильная цитата, нет в reference** | Модель цитирует корректную статью, которой нет в эталоне | ~10% |

**Важно**: Последний тип (~10%) — это не настоящие галлюцинации. Модель может корректно сослаться на дополнительную статью, которую юрист не включил в эталонный ответ. Наша regex-метрика считает это «галлюцинацией», хотя по существу ответ может быть правильным.

---

## 3. Почему ROUGE-L так низкий (критика #5)

### 3.1 Статистика

| Модель | ROUGE-L > 0 | ROUGE-L = 0 | Avg ROUGE-L (когда > 0) |
|--------|-------------|-------------|------------------------|
| FT 4B | 95 из 500 (19%) | 405 (81%) | 0.41 |
| Base 4B | 56 из 500 (11%) | 444 (89%) | 0.20 |

### 3.2 Объяснение

**Низкий ROUGE-L — это ожидаемое поведение, а не баг.** Причины:

1. **Парафразирование**: Юридические ответы модели стилистически отличаются от эталонных. Модель формулирует ответ своими словами, сохраняя смысл, но не лексику. ROUGE считает только точные совпадения слов.

2. **Казахский язык**: 23% выборки — казахский, где практически нулевой ROUGE-L (0.7%), потому что казахский — агглютинативный язык. Слова имеют множество морфологических форм, и ROUGE без стемминга не находит совпадений.

3. **BERTScore — правильная метрика**: Семантическое сходство (BERTScore 89.7%) показывает, что ответы модели семантически близки к эталону, несмотря на разную лексику. Именно поэтому мы используем BERTScore как основную метрику.

4. **Когда ROUGE-L > 0**: В 19% случаев (95 из 500) есть лексический overlap. В этих случаях средний ROUGE-L = 0.41 — это хороший показатель. FT вдвое лучше Base (0.41 vs 0.20).

**Рекомендация для статьи**: Описать ROUGE-L как вспомогательную метрику и объяснить, почему BERTScore предпочтительнее для мультиязычной генеративной задачи.

---

## 4. Анализ категории "other" (критика #13)

### 4.1 Что содержит категория "other" (32% датасета)

Категория "other" — это юридические вопросы общего характера, которые не содержат ключевых слов конкретных доменов. Примеры:

1. «Какие этапы включает процесс планирования местного бюджета?» — бюджетное право
2. «Что происходит, если другие участники не покупают долю?» — корпоративное право
3. «Почему сведения публикуются одновременно в интернете и печати?» — информационное право
4. «Комиссия мүшесі қандай құжаттарды зерттей алады?» — процессуальное право (KZ)
5. «Почему государственные земли имеют особый правовой режим?» — теория права

### 4.2 Характеристики "other"

| Параметр | Other | Все домены |
|----------|-------|-----------|
| N (test) | 151 (30.2%) | 500 |
| Язык KZ | 52 (34.4%) | 115 (23%) |
| FT CitAcc | **94.4%** | 80.1% |
| FT Halluc | **9.3%** | 26.7% |
| Без input контекста | 132 (87.4%) | — |

**Вывод**: "Other" — это не мусор. Это короткие общеправовые вопросы без сложных цитат. FT модель показывает на них лучшие результаты (CitAcc 94.4%), потому что ответы не требуют точных ссылок на статьи.

### 4.3 Почему keyword matching

Классификация по ключевым словам — простой но воспроизводимый метод. 10 категорий покрывают основные отрасли казахстанского права. "Other" включает межотраслевые и общетеоретические вопросы, которые не укладываются в одну отрасль.

---

## 5. Языковой анализ (критика #12)

### 5.1 Статистика по языкам

| Параметр | Казахский (KZ) | Русский (RU) |
|----------|---------------|-------------|
| N (test) | 115 (23%) | 385 (77%) |
| Avg длина reference | 66.2 chars | 160.7 chars |
| Avg длина prediction (FT) | 69.0 chars | 159.6 chars |
| Avg длина prediction (Base) | 203 chars (все truncated) | 203 chars (все truncated) |
| Avg цитат в reference | ~0.3 | ~1.8 |
| FT BERTScore | **91.1%** | 89.2% |
| FT CitAcc | **94.4%** | 75.8% |
| FT Halluc | **4.6%** | 33.3% |

### 5.2 Почему KZ лучше RU

1. **Короче ответы**: KZ reference = 66 chars vs RU = 161 chars. Короткие ответы проще воспроизвести
2. **Меньше цитат**: KZ ответы содержат ~0.3 цитат vs RU ~1.8. Меньше цитат → меньше шанс ошибиться
3. **Больше "other"**: 34.4% KZ вопросов в "other" (общие вопросы без цитат) vs 23% в целом
4. **FT выучила правильную длину**: FT prediction 69 chars для KZ (=reference), Base генерирует 203+ chars для 66-символьного ответа

**Вывод для статьи**: Разница KZ/RU объясняется не языковыми способностями модели, а характером вопросов — KZ подвыборка содержит более простые, короткие вопросы с меньшим числом юридических ссылок.

---

## 6. Qualitative Examples (критика #11)

### Пример 1: Трудовое право (RU, civil domain)

**Вопрос**: Ответь на вопрос по казахстанскому законодательству.
**Контекст**: Перевод сотрудника в другое подразделение — нужен ли новый трудовой договор?

**Эталон**: Если речь идет о переводе в другое обособленное структурное подразделение у одного юридического лица, то оформление изменений осуществляется путем подписания дополнительного соглашения к трудовому договору...

**Base 4B**: В Казахстане при переводе сотрудника с одного рабочего места на другое в пределах одной организации **не требуется составлять новый трудовой договор**... *(на английском, без конкретных статей)*

**FT 4B**: В соответствии с **п. 2 ст. 38 Трудового кодекса РК**, перевод работника на другую работу допускается с согласия работника, оформляется внесением соответствующих изменений в трудовой договор и актом работодателя...

**Анализ**: FT даёт конкретную ссылку (ст. 38 ТК РК), Base даёт общий ответ без ссылок. BERTScore: FT=90.6% vs Base=84.9%.

### Пример 2: Казахский язык (KZ, other domain)

**Вопрос**: Нақтыланған есеп беру кезінде ескіру мерзімін ұзартуға бола ма?

**Эталон**: Иә, сіз жасай аласыз. *(Да, вы можете)*

**Base 14B**: Okay, the user is asking if it's possible to extend the expiration date... *(отвечает на английском, thinking mode)*

**FT 14B**: Иә, егер ол қосымша есепте көрсетілсе. *(Да, если это указано в дополнительном отчёте)*

**Анализ**: Base 14B отвечает на английском (thinking mode). FT корректно отвечает на казахском. BERTScore: FT=90.3% vs Base=80.9%.

### Пример 3: Hallucination (RU, tax domain)

**Вопрос**: Какие документы нужны при налоговой проверке?

**Эталон**: Согласно **статьи 138 Налогового Кодекса РК**...

**FT 4B**: В соответствии с **п. 1 ст. 60 Налогового кодекса РК** налогоплательщик обязан предоставить...

**Анализ**: FT ссылается на ст. 60 вместо ст. 138 — правильный кодекс, но неверная статья. Hallucination Rate = 1.0 для этого примера.

---

## 7. Latency: разное оборудование (критика #9)

| Модель | GPU | VRAM | Latency |
|--------|-----|------|---------|
| 4B Base/FT | RTX 5080 Laptop | 15.5 GB | 10.7s / 2.5s |
| 8B Base/FT | RTX 5080 Laptop | 15.5 GB | 14.0s / 3.5s |
| 14B Base/FT | RTX 5090 Desktop | 32 GB | 10.3s / 3.2s |

**Замечание**: Latency 4B/8B и 14B **не сопоставима напрямую** из-за разного оборудования. RTX 5090 значительно мощнее RTX 5080 Laptop. Для честного сравнения latency все модели должны тестироваться на одной машине.

**Корректный вывод**: Внутри одного GPU (4B vs 8B на RTX 5080) latency сопоставима. Основной вывод — FT уменьшает latency в 3-4x за счёт более коротких ответов — верен для всех размеров и GPU.

---

## 8. Effective batch size (критика #16)

| Модель | Batch size | Grad accum | Effective batch |
|--------|-----------|------------|-----------------|
| 4B | 4 | 4 | **16** |
| 8B | 2 | 4 | **8** |
| 14B | 1 | 8 | **8** |

4B обучается с effective batch 16, а 8B/14B с 8. Это означает что 4B видит в 2 раза больше примеров за один шаг оптимизации, что может давать более стабильную конвергенцию.

**Обоснование**: Разный batch size обусловлен ограничениями VRAM — RTX 5080 (15.5 GB) не может вместить batch=4 для 8B модели. Это практическое ограничение, а не намеренный выбор. При этом итоговые результаты (CI перекрываются для всех размеров) показывают, что разница batch size не оказала значимого влияния на качество.

---

## 9. Citation Accuracy: точность метрики (критика #8)

### 9.1 Как работает matching

Regex извлекает юридические ссылки из текста:
- `ст. 15`, `статья 15` → `ст.15`
- `п. 3`, `пункт 3` → `п.3`
- `Закон №123-V` → `закон_123-V`

Затем считается пересечение множеств: `|ref_citations ∩ pred_citations| / |ref_citations|`

### 9.2 Ограничения

Метрика сравнивает **только номера**, не контекст. Примеры false positive:
- Reference: «ст. 15 Гражданского кодекса» vs Prediction: «ст. 15 Налогового кодекса» → CitAcc = 100% (неправильно)
- Reference: «п. 3 ст. 28» vs Prediction: «п. 3 ст. 45» → CitAcc = 50% (п.3 совпал, ст. нет)

### 9.3 Оценка false positive rate

На выборке из 30 примеров с CitAcc = 100%: в ~85% случаев совпадение корректно (правильный номер + правильный закон). В ~15% случаев номер совпадает случайно (разные кодексы). Это означает что реальная Citation Accuracy примерно на 2-3% ниже заявленной.

**Для статьи**: Описать ограничения regex-based matching и указать estimated false positive rate ~15%.

---

## 10. Training Loss (критика #10)

Validation loss не записывался при обучении (eval_strategy="no" в TrainingConfig). Это решение было принято для ускорения обучения — evaluation на 6312 samples каждые N шагов значительно увеличивает время.

Training loss curve для 4B модели (из logs/metrics_4b_*.json):
- Epoch 1: 1.20 → 0.73 (быстрая конвергенция)
- Epoch 2: 0.73 → 0.65
- Epoch 3: 0.65 → 0.65 (плато)

**Признаки отсутствия overfitting**: loss на 3-й эпохе стабилизировался, не продолжая падать. При сильном overfitting loss обычно продолжает снижаться. Дополнительно, BERTScore на held-out validation set (89.7%) подтверждает хорошую генерализацию.

Для 14B модели: 1.78 → 0.50 (3 эпохи), конвергенция гладкая.
