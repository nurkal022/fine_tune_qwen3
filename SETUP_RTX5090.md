# –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ –ø–µ—Ä–µ–Ω–æ—Å—É –Ω–∞ RTX 5090

–ü–æ–¥—Ä–æ–±–Ω–∞—è –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –æ–±—É—á–µ–Ω–∏—è Qwen3-32B –Ω–∞ –∫–æ–º–ø—å—é—Ç–µ—Ä–µ —Å –≤–∏–¥–µ–æ–∫–∞—Ä—Ç–æ–π NVIDIA RTX 5090 (32GB VRAM).

## üìã –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ

1. [–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è](#—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è)
2. [–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è](#—É—Å—Ç–∞–Ω–æ–≤–∫–∞-–æ–∫—Ä—É–∂–µ–Ω–∏—è)
3. [–ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è](#–∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ-—Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è)
4. [–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö](#–ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞-–¥–∞–Ω–Ω—ã—Ö)
5. [–ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è](#–∑–∞–ø—É—Å–∫-–æ–±—É—á–µ–Ω–∏—è)
6. [–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥](#–º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥)
7. [–£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º](#—É—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ-–ø—Ä–æ–±–ª–µ–º)

---

## üñ•Ô∏è –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è

### –ê–ø–ø–∞—Ä–∞—Ç–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è

- **–í–∏–¥–µ–æ–∫–∞—Ä—Ç–∞:** NVIDIA RTX 5090 (32GB GDDR7 VRAM)
- **CPU:** –ú–Ω–æ–≥–æ—è–¥–µ—Ä–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 16+ —è–¥–µ—Ä)
- **RAM:** –ú–∏–Ω–∏–º—É–º 64GB, —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è 128GB+
- **–î–∏—Å–∫:** SSD —Å –º–∏–Ω–∏–º—É–º 200GB —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –º–µ—Å—Ç–∞
- **–ë–ª–æ–∫ –ø–∏—Ç–∞–Ω–∏—è:** 1000W+ (RTX 5090 –ø–æ—Ç—Ä–µ–±–ª—è–µ—Ç –¥–æ 575W)

### –ü—Ä–æ–≥—Ä–∞–º–º–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è

- **–û–°:** Linux (Ubuntu 22.04+ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è) –∏–ª–∏ Windows 11
- **Python:** 3.10 –∏–ª–∏ 3.11
- **CUDA:** 12.4+ (–¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã Blackwell)
- **–î—Ä–∞–π–≤–µ—Ä—ã NVIDIA:** –ü–æ—Å–ª–µ–¥–Ω—è—è –≤–µ—Ä—Å–∏—è (560+)

---

## üîß –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è

### 1. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –¥—Ä–∞–π–≤–µ—Ä–æ–≤ NVIDIA

```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ–∫—É—â–µ–π –≤–µ—Ä—Å–∏–∏
nvidia-smi

# –ï—Å–ª–∏ –Ω—É–∂–Ω–æ –æ–±–Ω–æ–≤–∏—Ç—å (Ubuntu):
sudo apt update
sudo apt install nvidia-driver-560
sudo reboot
```

### 2. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ CUDA Toolkit

```bash
# Ubuntu
wget https://developer.download.nvidia.com/compute/cuda/12.4.0/local_installers/cuda_12.4.0_550.54.15_linux.run
sudo sh cuda_12.4.0_550.54.15_linux.run

# –î–æ–±–∞–≤–∏—Ç—å –≤ ~/.bashrc
export PATH=/usr/local/cuda-12.4/bin:$PATH
export LD_LIBRARY_PATH=/usr/local/cuda-12.4/lib64:$LD_LIBRARY_PATH
```

### 3. –°–æ–∑–¥–∞–Ω–∏–µ Conda –æ–∫—Ä—É–∂–µ–Ω–∏—è

```bash
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Miniconda (–µ—Å–ª–∏ –Ω–µ—Ç)
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
bash Miniconda3-latest-Linux-x86_64.sh

# –°–æ–∑–¥–∞–Ω–∏–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
conda create -n ai python=3.11 -y
conda activate ai
```

### 4. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ PyTorch

```bash
# PyTorch —Å CUDA 12.4 (–¥–ª—è RTX 5090)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA available: {torch.cuda.is_available()}'); print(f'Device: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"N/A\"}')"
```

**–û–∂–∏–¥–∞–µ–º—ã–π –≤—ã–≤–æ–¥:**
```
PyTorch: 2.x.x+cu124
CUDA available: True
Device: NVIDIA GeForce RTX 5090
```

### 5. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Unsloth –∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π

```bash
# Unsloth (–ø–æ—Å–ª–µ–¥–Ω—è—è –≤–µ—Ä—Å–∏—è)
pip install "unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git"

# –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ (–±–µ–∑ –ø–µ—Ä–µ—É—Å—Ç–∞–Ω–æ–≤–∫–∏)
pip install --no-deps xformers trl peft accelerate bitsandbytes

# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
pip install datasets matplotlib seaborn jupyter

# –ü—Ä–æ–≤–µ—Ä–∫–∞
python -c "from unsloth import FastLanguageModel; print('‚úÖ Unsloth —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω')"
```

---

## üì• –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è

```bash
# –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ
git clone https://github.com/nurkal022/fine_tune_qwen3.git
cd fine_tune_qwen3

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
ls -la
```

**–û–∂–∏–¥–∞–µ–º–∞—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∞:**
```
fine_tune_qwen3/
‚îú‚îÄ‚îÄ train_8b.py          # –û–±—É—á–µ–Ω–∏–µ 8B –º–æ–¥–µ–ª–∏
‚îú‚îÄ‚îÄ train_32b.py         # –û–±—É—á–µ–Ω–∏–µ 32B –º–æ–¥–µ–ª–∏ (–¥–ª—è RTX 5090)
‚îú‚îÄ‚îÄ combined_data/       # –î–∞—Ç–∞—Å–µ—Ç—ã
‚îú‚îÄ‚îÄ config.py            # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
‚îî‚îÄ‚îÄ ...
```

---

## üìä –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö

### –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –¥–∞–Ω–Ω—ã—Ö

```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–æ–≤
ls -lh combined_data/
# –î–æ–ª–∂–Ω—ã –±—ã—Ç—å:
# - train.jsonl
# - validation.jsonl
```

### –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç

```bash
# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
python prepare_data.py
```

---

## üöÄ –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è

### –í–∞—Ä–∏–∞–Ω—Ç 1: –û–±—É—á–µ–Ω–∏–µ Qwen3-32B (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è RTX 5090)

```bash
conda activate ai
python train_32b.py
```

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è 32B:**
- Batch size: 1
- Gradient accumulation: 8 (—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π batch = 8)
- Max sequence length: 1024
- LoRA r: 32
- Learning rate: 1e-4

### –í–∞—Ä–∏–∞–Ω—Ç 2: –û–±—É—á–µ–Ω–∏–µ Qwen3-8B (–±—ã—Å—Ç—Ä–µ–µ, –º–µ–Ω—å—à–µ –ø–∞–º—è—Ç–∏)

```bash
conda activate ai
python train_8b.py
```

### –í–∞—Ä–∏–∞–Ω—Ç 3: Jupyter Notebook (–∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–æ)

```bash
jupyter notebook train_qwen3.ipynb
```

–í notebook –∏–∑–º–µ–Ω–∏ `MODEL_VERSION = "32B"` –¥–ª—è –æ–±—É—á–µ–Ω–∏—è 32B –º–æ–¥–µ–ª–∏.

---

## üìà –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥

### –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ GPU –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏

```bash
# –í –æ—Ç–¥–µ–ª—å–Ω–æ–º —Ç–µ—Ä–º–∏–Ω–∞–ª–µ
watch -n 1 nvidia-smi
```

### –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏

```python
# –í Python
import torch
print(f"Reserved: {torch.cuda.max_memory_reserved() / 1024**3:.2f} GB")
print(f"Allocated: {torch.cuda.memory_allocated() / 1024**3:.2f} GB")
```

### –û–∂–∏–¥–∞–µ–º–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ –¥–ª—è 32B:

| –ö–æ–º–ø–æ–Ω–µ–Ω—Ç | –ü–∞–º—è—Ç—å |
|-----------|--------|
| –í–µ—Å–∞ –º–æ–¥–µ–ª–∏ (4-bit) | ~16 GB |
| LoRA –∞–¥–∞–ø—Ç–µ—Ä—ã | ~0.5 GB |
| –ì—Ä–∞–¥–∏–µ–Ω—Ç—ã + –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ | ~8-12 GB |
| KV-cache | ~2-4 GB |
| **–ò—Ç–æ–≥–æ** | **~28-32 GB** |

---

## ‚ö†Ô∏è –£—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º

### –ü—Ä–æ–±–ª–µ–º–∞: Out of Memory (OOM)

**–†–µ—à–µ–Ω–∏–µ:**
1. –£–º–µ–Ω—å—à–∏—Ç—å `MAX_SEQ_LENGTH` –¥–æ 512
2. –£–º–µ–Ω—å—à–∏—Ç—å `BATCH_SIZE` –¥–æ 1 (—É–∂–µ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π)
3. –£–≤–µ–ª–∏—á–∏—Ç—å `GRAD_ACCUM` –¥–æ 16
4. –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ –Ω–µ—Ç –¥—Ä—É–≥–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –Ω–∞ GPU

```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –Ω–∞ GPU
nvidia-smi

# –£–±–∏—Ç—å –ø—Ä–æ—Ü–µ—Å—Å (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ)
kill -9 <PID>
```

### –ü—Ä–æ–±–ª–µ–º–∞: –ú–µ–¥–ª–µ–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ

**–ü—Ä–∏—á–∏–Ω—ã:**
- 32B –º–æ–¥–µ–ª—å —Ç—Ä–µ–±—É–µ—Ç –º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ (–Ω–µ—Å–∫–æ–ª—å–∫–æ —á–∞—Å–æ–≤)
- –ü—Ä–æ–≤–µ—Ä—å, —á—Ç–æ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è GPU, –∞ –Ω–µ CPU

**–ü—Ä–æ–≤–µ—Ä–∫–∞:**
```python
import torch
print(torch.cuda.is_available())  # –î–æ–ª–∂–Ω–æ –±—ã—Ç—å True
print(torch.cuda.get_device_name(0))  # –î–æ–ª–∂–Ω–æ –ø–æ–∫–∞–∑–∞—Ç—å RTX 5090
```

### –ü—Ä–æ–±–ª–µ–º–∞: –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏

**–†–µ—à–µ–Ω–∏–µ:**
```bash
# –û—á–∏—Å—Ç–∫–∞ –∫–µ—à–∞ HuggingFace
rm -rf ~/.cache/huggingface/hub

# –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞
python train_32b.py
```

### –ü—Ä–æ–±–ª–µ–º–∞: CUDA –≤–µ—Ä—Å–∏—è –Ω–µ —Å–æ–≤–º–µ—Å—Ç–∏–º–∞

**–†–µ—à–µ–Ω–∏–µ:**
```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–µ—Ä—Å–∏–∏ CUDA
nvcc --version
python -c "import torch; print(torch.version.cuda)"

# –î–æ–ª–∂–Ω—ã —Å–æ–≤–ø–∞–¥–∞—Ç—å –∏–ª–∏ –±—ã—Ç—å —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–º–∏
```

---

## üìù –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤

### –î–ª—è —É–≤–µ–ª–∏—á–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞ (–µ—Å–ª–∏ –µ—Å—Ç—å –∑–∞–ø–∞—Å –ø–∞–º—è—Ç–∏):

–í `train_32b.py` –∏–∑–º–µ–Ω–∏:

```python
MAX_SEQ_LENGTH = 2048  # –±—ã–ª–æ 1024
LORA_R = 64           # –±—ã–ª–æ 32
BATCH_SIZE = 2        # –±—ã–ª–æ 1 (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –≤–ª–µ–∑–∞–µ—Ç!)
```

### –î–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è:

```python
SAVE_STEPS = 500      # –±—ã–ª–æ 200 (—Ä–µ–∂–µ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å)
GRAD_ACCUM = 4        # –±—ã–ª–æ 8 (–º–µ–Ω—å—à–µ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏–µ)
```

---

## ‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤

–ü–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è:

```bash
# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
ls -lh finetuned_qwen3_32b/
ls -lh lora_qwen3_32b/

# –ü—Ä–æ–≤–µ—Ä–∫–∞ —á–µ–∫–ø–æ–∏–Ω—Ç–æ–≤
ls -lh outputs_32b/
```

### –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏

```bash
python chat.py
# –ò–ª–∏
python test_8b.py  # (–∞–¥–∞–ø—Ç–∏—Ä—É–π –¥–ª—è 32B)
```

---

## üìö –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

- [Unsloth Documentation](https://github.com/unslothai/unsloth)
- [Qwen3 Models](https://huggingface.co/Qwen)
- [RTX 5090 Specifications](https://www.nvidia.com/en-us/geforce/graphics-cards/rtx-5090/)

---

## üÜò –ü–æ–¥–¥–µ—Ä–∂–∫–∞

–ï—Å–ª–∏ –≤–æ–∑–Ω–∏–∫–ª–∏ –ø—Ä–æ–±–ª–µ–º—ã:

1. –ü—Ä–æ–≤–µ—Ä—å –ª–æ–≥–∏ –æ–±—É—á–µ–Ω–∏—è
2. –£–±–µ–¥–∏—Å—å, —á—Ç–æ –≤—Å–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω—ã
3. –ü—Ä–æ–≤–µ—Ä—å —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –≤–µ—Ä—Å–∏–π CUDA/PyTorch
4. –°–æ–∑–¥–∞–π issue –≤ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–∏

---

**–£–¥–∞—á–∏ —Å –æ–±—É—á–µ–Ω–∏–µ–º! üöÄ**

