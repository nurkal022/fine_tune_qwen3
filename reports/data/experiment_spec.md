# Спецификация эксперимента

Формальное описание постановки эксперимента для раздела «Методология» статьи.

---

## 1. Цель

Обучить языковую модель Qwen3-8B на датасете «вопрос–ответ» по казахстанскому законодательству и оценить качество ответов на отложенной выборке.

---

## 2. Модель

- **Архитектура:** Qwen3 (Decoder-only LLM), 8B параметров.
- **Источник:** `unsloth/Qwen3-8B-unsloth-bnb-4bit` (предобученная модель с 4-bit квантизацией).
- **Адаптация:** LoRA (Low-Rank Adaptation):
  - target modules: `q_proj`, `k_proj`, `v_proj`, `o_proj`, `gate_proj`, `up_proj`, `down_proj`;
  - rank r = 16, alpha = 16, dropout = 0;
  - bias = none;
  - gradient checkpointing: unsloth.
- **Квантизация:** 4-bit (NF4) на всём времени обучения и инференса.
- **Максимальная длина последовательности:** 2048 токенов.

---

## 3. Данные

- **Формат:** JSONL, поля `instruction`, `input`, `output`.
- **Разделы:** train — 56 802 примера; validation — 6 312 примеров.
- **Языки:** русский и казахский.
- **Домен:** законодательство Республики Казахстан (трудовое, налоговое, гражданское, земельное право и др.).
- **Шаблон промпта:** Alpaca-style (Instruction / Input / Response).

---

## 4. Обучение

- **Среда:** PyTorch 2.9.1, CUDA 12.0, Unsloth 2025.12.1.
- **Оборудование:** 1× NVIDIA RTX 5080 Laptop, 15.5 GB VRAM.
- **Гиперпараметры:**
  - batch size per device = 2;
  - gradient accumulation steps = 4 (effective batch size = 8);
  - эпохи = 3;
  - learning rate = 2e-4;
  - optimizer = AdamW 8-bit;
  - lr scheduler = linear с warmup (warmup_ratio = 0.03);
  - weight decay = 0.001;
  - bf16 = true;
  - save_steps = 1000, logging_steps = 50.
- **Длительность:** ~23.9 ч, 21 303 шага.
- **Итоговые метрики обучения:** train_loss ≈ 0.7055; снижение loss по логу от 1.85 до ~0.56 (~69.6%).

---

## 5. Оценка

- **Выборка:** 100 случайных примеров из validation (seed фиксирован в скрипте бенчмарка).
- **Генерация:** max_new_tokens = 512, temperature = 0.1, top_p = 0.9; без beam search.
- **Метрики:**
  - **Token F1** — F1 по совпадению слов между ответом модели и эталоном.
  - **Exact Match** — доля точного (нормализованного) совпадения ответа с эталоном.
  - **Key Info Score** — сохранение ключевой информации (числа, ссылки на нормы, термины).
  - **Length Ratio** — отношение длины ответа к длине эталона (с учётом штрафа за сильное отклонение).

---

## 6. Воспроизводимость

- Скрипты: `train_8b.py`, `benchmark.py`, `generate_plots.py`.
- Конфигурация обучения: `data/config_20260127_095201.json`.
- Метрики обучения: `data/metrics_20260127_095201.json`.
- Результаты бенчмарка: `data/benchmark_results_20260128_214117.json`.
- Сводка: `data/training_summary_20260204_112506.json`.
